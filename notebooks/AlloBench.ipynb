{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc19951-a31c-4292-aa65-8eb6f63a765f",
   "metadata": {},
   "source": [
    "# Merge Allosteric Site Database with Active Site Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6858e-8d0c-4716-8f45-6a0b7afd75f6",
   "metadata": {},
   "source": [
    "TODO: Fix Active Site annotation with respect to PDB and not Uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897035ae-250a-41b2-a63a-62967052f52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import xmltodict\n",
    "from SPARQLWrapper import JSON, SPARQLWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4f668-e536-4370-bc54-87da02e211c6",
   "metadata": {},
   "source": [
    "## Input and Output Filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d2cc1-6ed8-4b36-b4be-87aa948c200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd_xml_dir = '../data/ASD_Release_202306_XF/'    # path to directory containing extracted ASD XML files\n",
    "asd_csv_file = '../output/ASD_Release_202306.csv'  # file to save the converted CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9523290c-85b4-4dd0-af3b-ac8e4301a691",
   "metadata": {},
   "source": [
    "## Recreate the ASD_Release_202306.txt tab separated table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2cf4d0-f82b-4466-a1eb-2dc2f8cb8dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_allosteric_site(alloteric_site):\n",
    "    \"\"\"Convert the list of residues in ASD from \"Chain A:HIS25,TYR258; Chain B:VAL325\" to ['A-HIS-25', 'A-TYR-258', 'B-VAL-325']\"\"\"\n",
    "    residues = []\n",
    "    for chain_string in alloteric_site.split('; '):\n",
    "        chain_name, residue_string = chain_string.split(':')\n",
    "        chain_id = chain_name[-1]\n",
    "        for residue in residue_string.split(','):\n",
    "            res_name, res_id = residue[:3], residue[3:]\n",
    "            residues.append(f'{chain_id}-{res_name}-{res_id}')\n",
    "    return residues\n",
    "\n",
    "\n",
    "def parse_asd_xml(asd_xml_dir):\n",
    "    data = []\n",
    "    for xml_file in tqdm(glob(os.path.join(asd_xml_dir, '*.xml'))):\n",
    "        xml_string = open(xml_file, 'r').read()\n",
    "        xml_string = xml_string.replace('&#x2;', '')  # Remove invalid XML character\n",
    "        protein = xmltodict.parse(xml_string)\n",
    "    \n",
    "        target_gene = ''\n",
    "        target_id = protein['Organism_Record']['Organism_ID']\n",
    "    \n",
    "        if 'Gene' in protein['Organism_Record'] and 'Gene_Name' in protein['Organism_Record']['Gene']:\n",
    "            target_gene = protein['Organism_Record']['Gene']['Gene_Name']\n",
    "    \n",
    "        organism = protein['Organism_Record']['Organism']\n",
    "    \n",
    "        # Check if the list of allosteric sites in present in the XML file\n",
    "        if 'Allosteric_Site_List' in protein['Organism_Record']:\n",
    "            allosteric_sites = protein['Organism_Record']['Allosteric_Site_List']['Allosteric_Site']\n",
    "    \n",
    "            # Check if more than one allosteric site is present\n",
    "            if isinstance(allosteric_sites, list):\n",
    "                allosteric_sites = allosteric_sites\n",
    "            else:\n",
    "                allosteric_sites = [allosteric_sites]\n",
    "        else:\n",
    "            allosteric_sites = []\n",
    "    \n",
    "        for site in allosteric_sites:\n",
    "            if site:\n",
    "                pdb_uniprot = site['PDB_UniProt_ID'] if 'PDB_UniProt_ID' in site else ''\n",
    "                allosteric_pdb = site['Allosteric_PDB']\n",
    "                modulator_serial = site['Modulator_ASD_ID']\n",
    "                modulator_alias = site['Modulator_Alias']\n",
    "                modulator_chain = site['Modulator_Chain']\n",
    "                modulator_class = site['Modulator_Class'] if 'Modulator_Class' in site else ''\n",
    "                modulator_feature = site['Modulator_Feature'] if 'Modulator_Feature' in site else ''\n",
    "                modulator_name = site['Modulator_Name'] if 'Modulator_Name' in site else ''\n",
    "                modulator_resi = site['Modulator_Residue'] if 'Modulator_Residue' in site else ''\n",
    "                function = site['Function'] if 'Function' in site else ''\n",
    "                position = site['Position'] if 'Position' in site else ''\n",
    "                pubmed_id = site['PubMed_ID'] if 'PubMed_ID' in site else ''\n",
    "                ref_title = site['PubMed_Title'] if 'PubMed_Title' in site else ''\n",
    "                site_overlap = site['Site_Overlap'] if 'Site_Overlap' in site else ''\n",
    "                allosteric_site_residue = parse_allosteric_site(site['Allosteric_Site_Residue']) if 'Allosteric_Site_Residue' in site else []\n",
    "    \n",
    "                data.append([\n",
    "                    target_id, target_gene, organism, pdb_uniprot, allosteric_pdb,\n",
    "                    modulator_serial, modulator_alias, modulator_chain,\n",
    "                    modulator_class, modulator_feature, modulator_name,\n",
    "                    modulator_resi, function, position, pubmed_id, ref_title,\n",
    "                    site_overlap, allosteric_site_residue])\n",
    "    \n",
    "    return pd.DataFrame(data, columns=[\n",
    "        'target_id', 'target_gene', 'organism', 'pdb_uniprot', 'allosteric_pdb',\n",
    "        'modulator_serial', 'modulator_alias', 'modulator_chain', 'modulator_class',\n",
    "        'modulator_feature', 'modulator_name', 'modulator_resi', 'function',\n",
    "        'position', 'pubmed_id', 'ref_title', 'site_overlap',\n",
    "        'allosteric_site_residues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3055a-f540-4b7a-a89a-102ee6748b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asd = parse_asd_xml(asd_xml_dir)\n",
    "# Make the UniProt and PDB IDs uppercase to facilitate merging on these later\n",
    "df_asd['allosteric_pdb'] = df_asd['allosteric_pdb'].str.upper()\n",
    "df_asd['pdb_uniprot'] = df_asd['pdb_uniprot'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b35a45-772c-4a7c-891e-ee98c29f437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Rows:             ', df_asd.shape[0])\n",
    "print('Number of Unique PDB IDs:   ', df_asd['allosteric_pdb'].nunique())\n",
    "print('Number of Unique UniProt AC:', df_asd['pdb_uniprot'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc35a2-f36f-43e5-89fe-7d5d47bc02e4",
   "metadata": {},
   "source": [
    "## Fix Obsolete PDB Entries\n",
    "\n",
    "The list of obsolete PDB IDs are downloaded from the World Wide Protein Data Bank\n",
    "\n",
    "While most obsolete PDB IDs have been superseded by only one PDB ID. There exists PDB IDs superseded by multiple PDB IDs. For such cases we select the last PDB ID in the list assuming that it will be the latest one. Obsolete entries without a superseded PDB ID are be removed. \n",
    "\n",
    "However, in the ASD dataframe (`df_asd`) each obsolete PDB ID had only one superseded PDB ID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b70b3-a462-48c3-97b1-a9381d78c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://files.wwpdb.org/pub/pdb/holdings/all_removed_entries.json.gz')\n",
    "\n",
    "obsolete_pdb = {}\n",
    "for pdb_id, value in json.loads(gzip.decompress(response.content)).items():\n",
    "    if 'superseded_by' in value:\n",
    "        # Select the last element in the list of superseded PDB IDs\n",
    "        obsolete_pdb[pdb_id] = value['superseded_by'][-1] \n",
    "    else:\n",
    "        obsolete_pdb[pdb_id] = []\n",
    "\n",
    "print('Number of Obsolete PDB IDs:', len(obsolete_pdb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce64ab-aa89-43ee-a509-6b7959213bbc",
   "metadata": {},
   "source": [
    "Obsolete and superseded PDB IDs in ASD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c83e13-3e08-4431-9339-3ef222e9d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asd['allosteric_pdb'] = df_asd['allosteric_pdb'].replace(obsolete_pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3855d8e7-57ac-42ce-9ce0-e0b3078fbe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Rows:             ', df_asd.shape[0])\n",
    "print('Number of Unique PDB IDs:   ', df_asd['allosteric_pdb'].nunique())\n",
    "print('Number of Unique UniProt AC:', df_asd['pdb_uniprot'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c17fcf-6e50-4b89-89cb-2b934f9aecd4",
   "metadata": {},
   "source": [
    "## Fix Obsolete UniProt Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36112db6-7866-4cf8-b93a-de1964f5b5ef",
   "metadata": {},
   "source": [
    "Get PDB to UniProt Mapping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87a492-8d9f-478b-8074-26ae0ddd2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniprot_from_pdb(pdb_ids):\n",
    "    pdb_ids_string = '\", \"'.join(pdb_ids)\n",
    "\n",
    "    body = 'query {entries(entry_ids: [\"' + pdb_ids_string + '\"])' + \"\"\"\n",
    "      {\n",
    "        rcsb_id\n",
    "        polymer_entities {\n",
    "          uniprots {\n",
    "            rcsb_id\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    response = requests.post(url='https://data.rcsb.org/graphql', json={\"query\": body})\n",
    "    response_data = response.json()\n",
    "\n",
    "    id_mapping = []\n",
    "    for record in response_data['data']['entries']:\n",
    "        rcsb_id = record['rcsb_id']\n",
    "        uniprot_ids = set()\n",
    "        for entity in record['polymer_entities']:\n",
    "            if entity['uniprots']:\n",
    "                uniprot_ids.add(entity['uniprots'][0]['rcsb_id'])\n",
    "        id_mapping.append([rcsb_id, uniprot_ids])\n",
    "        \n",
    "    return pd.DataFrame(id_mapping, columns=['pdb_id', 'uniprot_id_from_pdb'])\n",
    "\n",
    "\n",
    "def uniprot_pdb_fix(df):\n",
    "    df_copy = df[['pdb_id', 'uniprot_id']].drop_duplicates().copy()\n",
    "\n",
    "    # Get the UniProt IDs of the chains in the proteins from PDB website\n",
    "    df_pdb = uniprot_from_pdb(df_copy['pdb_id'])\n",
    "    \n",
    "    # Count the number of UniProt IDs obtained from PDB website for each PDB ID\n",
    "    df_pdb['num_uniprot'] = df_pdb['uniprot_id_from_pdb'].apply(len)\n",
    "    \n",
    "    df_merged = df_copy.merge(df_pdb, how='left')\n",
    "\n",
    "    # Check if the UniProt ID in ASD is present in the UniProt IDs obtained from PDB website\n",
    "    df_merged['present'] = df_merged.apply(lambda x: x['uniprot_id'] in x['uniprot_id_from_pdb'], axis=1)\n",
    "    df_present = df_merged.loc[df_merged['present'], ['pdb_id', 'uniprot_id']]\n",
    "\n",
    "    # UniProt IDs absent in the ASD but has only one UniProt ID downloaded from PDB\n",
    "    df_absent_single = df_merged[~df_merged['present'] & (df_merged['num_uniprot'] == 1)].copy()\n",
    "    print(\"PDB IDs Absent from ASD with Single UniProt ID fetched from the PDB\")\n",
    "    display(df_absent_single)\n",
    "\n",
    "    # Place the only one UniProt ID from the set in Uniprot ID column to pdb_uniprot column\n",
    "    if not df_absent_single.empty:\n",
    "        df_absent_single['uniprot_id'] = df_absent_single.apply(lambda x: next(iter(x['uniprot_id_from_pdb'])), axis=1)\n",
    "    df_absent_single = df_absent_single[['pdb_id', 'uniprot_id']]\n",
    "    \n",
    "    df_absent_multiple = df_merged[~df_merged['present'] & (df_merged['num_uniprot'] != 1)]\n",
    "    print(\"PDB IDs Absent from ASD with Multiple UniProt ID fetched from the PDB\")\n",
    "    display(df_absent_multiple)\n",
    "\n",
    "    df_output = pd.concat([df_present, df_absent_single])\n",
    "    return df_output.sort_values(['pdb_id', 'uniprot_id']).reset_index(drop=True)\n",
    "\n",
    "def replace_obsolete_pdbs(pdb_set, obsolete_pdbs):\n",
    "    for pdb in pdb_set & set(obsolete_pdbs.keys()):\n",
    "        pdb_set.remove(pdb)\n",
    "        pdb_set.add(obsolete_pdbs[pdb])\n",
    "        print(f'PDB ID {pdb} has been superseded by {obsolete_pdbs[pdb]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35be42-4fce-4f9c-8005-f5e4531381b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asd_pdb_uniprot = df_asd[['allosteric_pdb', 'pdb_uniprot']].rename(\n",
    "    columns={'allosteric_pdb': 'pdb_id', 'pdb_uniprot': 'uniprot_id'}\n",
    ").drop_duplicates()\n",
    "\n",
    "df_asd_pdb_uniprot = uniprot_pdb_fix(df_asd_pdb_uniprot)\n",
    "\n",
    "# Reinsert PDB ID and UniProt AC combination from the manual curation of the table below\n",
    "df_manual_curation = pd.DataFrame([\n",
    "    ['1CKK', 'P0DP33'], ['1IQ5', 'P0DP33'], ['1NWD', 'P0DP33'],\n",
    "    ['3J41', 'P0DP23'], ['3OBK', 'S8F7E9'], ['3RHW', 'G5EBR3'],\n",
    "    ['3RI5', 'G5EBR3'], ['3RIA', 'G5EBR3'], ['3RIF', 'G5EBR3'],\n",
    "    ['4A2U', 'P9WP65'], ['4P86', 'P39765'], ['6KDY', 'O43837'],\n",
    "    ['6UI4', 'I1RCT2'], ['7LD3', 'P30542'], ['7O83', 'P01116']],\n",
    "    columns=['pdb_id', 'uniprot_id'])\n",
    "\n",
    "df_asd_pdb_uniprot = pd.concat([df_asd_pdb_uniprot, df_manual_curation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594ef17-8cff-4ee7-98d4-bb424f90f0da",
   "metadata": {},
   "source": [
    "The following PDB IDs from ASD were dropped: 3OWZ, 3OXM, 3OWI, 3Q3Z, 3OXJ, 3OWW, 3OXE because these are structures of glycine riboswitch, an RNA element and do not have an associated UniProt IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be08c83-1082-42e0-8e5e-87e2fb700b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asd_updated =  df_asd.drop(columns='pdb_uniprot').merge(\n",
    "    df_asd_pdb_uniprot.rename(columns={'pdb_id': 'allosteric_pdb',\n",
    "                                       'uniprot_id': 'pdb_uniprot'}),\n",
    "    on='allosteric_pdb'\n",
    ")\n",
    "\n",
    "df_asd_updated['allosteric_site_residues'] = df_asd_updated['allosteric_site_residues'].astype(str)\n",
    "df_asd_updated.drop_duplicates(inplace=True)\n",
    "\n",
    "df_asd_updated['allosteric_site_residues'] = df_asd_updated['allosteric_site_residues'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad4283e-a390-42fa-85cd-4e6ca315d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Rows:             ', df_asd_updated.shape[0])\n",
    "print('Number of Unique PDB IDs:   ', df_asd_updated['allosteric_pdb'].nunique())\n",
    "print('Number of Unique UniProt AC:', df_asd_updated['pdb_uniprot'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8e0c46-6d0e-471b-9ae5-df9edf7ab32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asd_updated[['target_id', 'target_gene', 'organism', 'pdb_uniprot', 'allosteric_pdb',\n",
    "       'modulator_serial', 'modulator_alias', 'modulator_chain',\n",
    "       'modulator_class', 'modulator_feature', 'modulator_name',\n",
    "       'modulator_resi', 'function', 'position', 'pubmed_id', 'ref_title',\n",
    "       'site_overlap', 'allosteric_site_residues'\n",
    "               ]].to_csv(asd_csv_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f9018d-1881-4758-87e0-ace7b6429b94",
   "metadata": {},
   "source": [
    "## Merge with Additional Information from the PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebcdca6-9f13-4bb6-b49a-e6da41e47c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdb = pd.read_csv('../data/ASD_PDB_chain_uniprot_oligomeric_state.csv')\n",
    "\n",
    "def get_chain_uniprot(array):\n",
    "    output = set()\n",
    "    if isinstance(array, str):\n",
    "        array = eval(array)\n",
    "    for chain in array:\n",
    "        for uniprot_id in chain[1]:\n",
    "            output.add(uniprot_id)\n",
    "    return sorted(output)\n",
    "\n",
    "df_pdb['chain_uniprot_mapping'] = df_pdb['chain_uniprot_mapping'].apply(eval)\n",
    "\n",
    "df_pdb['uniprot_in_pdb'] = df_pdb['chain_uniprot_mapping'].apply(get_chain_uniprot)\n",
    "\n",
    "df_pdb.rename(columns={'pdb_id': 'allosteric_pdb'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f961dfe6-f529-42ec-98bb-08c3d5de45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asd_with_active_site = df_asd_updated.merge(df_pdb)\n",
    "\n",
    "print('Number of Rows:             ', df_asd_with_active_site.shape[0])\n",
    "print('Number of Unique PDB IDs:   ', df_asd_with_active_site['allosteric_pdb'].nunique())\n",
    "print('Number of Unique UniProt AC:', df_asd_with_active_site['pdb_uniprot'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3ce1a-8a31-4ac5-abff-9ed1bd7362fc",
   "metadata": {},
   "source": [
    "## Get Catalytic Site Atlas Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f6fdc9-0c91-469f-89b2-a20ca3cd7dcc",
   "metadata": {},
   "source": [
    "1. Get the manually curated catalytic residues from the Mechanism and Catalytic Site Atlas (M-CSA)\n",
    "2. Parse the JSON file and create a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1b2cc-f167-4d63-88ff-0697f8c34e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://www.ebi.ac.uk/thornton-srv/m-csa/api/residues/?format=json')\n",
    "mcsa_data = response.json()\n",
    "\n",
    "output = []\n",
    "for i, entry in enumerate(mcsa_data):\n",
    "    if entry['residue_chains']:\n",
    "        chain_name          = entry['residue_chains'][0]['chain_name']\n",
    "        pdb_id              = entry['residue_chains'][0]['pdb_id'].upper()\n",
    "        assembly_chain_name = entry['residue_chains'][0]['assembly_chain_name']\n",
    "        assembly            = entry['residue_chains'][0]['assembly']\n",
    "        code                = entry['residue_chains'][0]['code']\n",
    "        resid               = entry['residue_chains'][0]['resid']\n",
    "    else:\n",
    "        chain_name          = ''\n",
    "        pdb_id              = ''\n",
    "        assembly_chain_name = ''\n",
    "        assembly            = ''\n",
    "        code                = ''\n",
    "        resid               = np.nan\n",
    "    uniprot_id          = entry['residue_sequences'][0]['uniprot_id']\n",
    "    res_seq_code        = entry['residue_sequences'][0]['code']\n",
    "    res_seq_resid       = entry['residue_sequences'][0]['resid']\n",
    "\n",
    "    output.append([chain_name, pdb_id, assembly_chain_name, assembly,\n",
    "                   code, resid, uniprot_id, res_seq_code, res_seq_resid])\n",
    "\n",
    "df_csa = pd.DataFrame(output, columns=['chain_name', 'pdb_id',\n",
    "                                       'assembly_chain_name', 'assembly',\n",
    "                                       'code', 'resid', 'uniprot_id',\n",
    "                                       'res_seq_code', 'res_seq_resid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb79aa-bce3-4256-9071-a085eb765514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the UniProt and PDB IDs uppercase to facilitate merging on these later\n",
    "df_csa['uniprot_id'] = df_csa['uniprot_id'].str.upper()\n",
    "df_csa['pdb_id'] = df_csa['pdb_id'].str.upper()\n",
    "\n",
    "# Replace the assembly_chain_name with chain_name if there are odd chain_name in assembly_chain_name column\n",
    "df_csa.loc[df_csa['assembly_chain_name'].str.len() > 1, 'assembly_chain_name'] = df_csa['chain_name']\n",
    "print('Number of UniProt IDs in M-CSA:', df_csa['uniprot_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d5cf8-9ecd-4696-8a1c-be32c28ad197",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Rows:             ', df_csa.shape[0])\n",
    "print('Number of Unique PDB IDs:   ', df_csa['pdb_id'].nunique())\n",
    "print('Number of Unique UniProt AC:', df_csa['uniprot_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa58820-65e9-4d07-8982-ee00aab23a23",
   "metadata": {},
   "source": [
    "3. Download M-CSA PDB IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00c6866-62c1-4ec4-bf7b-b50a98e1d439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniprot_from_pdb_chains(pdb_chains):\n",
    "    pdb_chains_string = '\", \"'.join(pdb_chains)\n",
    "    \n",
    "    body = 'query {polymer_entity_instances(instance_ids: [\"' + pdb_chains_string + '\"])' + \"\"\"\n",
    "      {\n",
    "        rcsb_id\n",
    "        polymer_entity {\n",
    "          uniprots {\n",
    "            rcsb_id\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    response = requests.post(url='https://data.rcsb.org/graphql', json={\"query\": body})\n",
    "    response_data = response.json()\n",
    "\n",
    "    id_mapping = []\n",
    "    for record in response_data['data']['polymer_entity_instances']:\n",
    "        rcsb_id, chain = record['rcsb_id'].split('.')\n",
    "        if record['polymer_entity']['uniprots'] is not None:\n",
    "            uniprot_id = record['polymer_entity']['uniprots'][0]['rcsb_id']\n",
    "        else:\n",
    "            uniprot_id = ''\n",
    "        id_mapping.append([rcsb_id, chain, uniprot_id])\n",
    "        \n",
    "    return pd.DataFrame(id_mapping, columns=['pdb_id', 'chain', 'uniprot_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a74c33b-3911-4732-ab8c-a015324da241",
   "metadata": {},
   "source": [
    "### Update obsolete UniProt IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61216d94-3aab-4f5d-a7ac-76f42466668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csa_pdb_chains = set(df_csa['pdb_id'] + '.' + df_csa['assembly_chain_name'])\n",
    "df_csa_pdb = uniprot_from_pdb_chains(csa_pdb_chains)\n",
    "df_csa_pdb = df_csa_pdb.rename(columns={'chain': 'assembly_chain_name', 'uniprot_id': 'UniProt_AC'})\n",
    "df_csa_merged = df_csa.merge(df_csa_pdb, how='left', on=['pdb_id', 'assembly_chain_name'])\n",
    "df_csa_merged.loc[(df_csa_merged['uniprot_id'] != df_csa_merged['UniProt_AC']) & ~df_csa_merged['UniProt_AC'].isna(), 'uniprot_id'] = df_csa_merged['UniProt_AC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d622fc7-fbca-45df-9511-bb47a2dfdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csa_merged_subset = df_csa_merged[['chain_name', 'pdb_id', 'assembly_chain_name', 'uniprot_id', 'UniProt_AC']].drop_duplicates()\n",
    "with pd.option_context('display.max_rows', 100, 'display.max_columns', 10):\n",
    "    display(\n",
    "        df_csa_merged_subset[df_csa_merged_subset['uniprot_id'] != df_csa_merged_subset['UniProt_AC']]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8c196-c30c-4d9f-ae08-3109374146d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csa_pdb_uniprot = df_csa_merged_subset[['pdb_id', 'uniprot_id']].drop_duplicates()\n",
    "print('Number of Rows:             ', df_csa_pdb_uniprot.shape[0])\n",
    "print('Number of Unique PDB IDs:   ', df_csa_pdb_uniprot['pdb_id'].nunique())\n",
    "print('Number of Unique UniProt AC:', df_csa_pdb_uniprot['uniprot_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed0bd94-408f-4e88-9549-ae5337135b0b",
   "metadata": {},
   "source": [
    "3. Filter the M-CSA data for proteins contained in the ASD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab936a67-c135-4045-b12e-29dca57cbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asd_updated = pd.read_csv(asd_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c74257-c321-42b0-ab8d-2938ed05ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csa_in_asd = df_csa_merged[df_csa_merged['UniProt_AC'].isin(df_asd_updated['pdb_uniprot'])].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012045e-8b74-4e5f-b30f-40b1fb358ae0",
   "metadata": {},
   "source": [
    "4. Group by PDB ID and UniProt ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd85ac00-63fd-4e29-9dca-4a405b29d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csa_in_asd['catalytic_site'] = (df_csa_in_asd['assembly_chain_name'] + '-'\n",
    "                                   + df_csa_in_asd['res_seq_resid'].astype(str)\n",
    "                                   + '-' + df_csa_in_asd['res_seq_code']\n",
    "                                   )\n",
    "\n",
    "df_csa_in_asd['catalytic_site_resids'] = (\n",
    "    df_csa_in_asd['res_seq_resid'])\n",
    "\n",
    "df_csa_in_asd_grouped = df_csa_in_asd[\n",
    "    ['UniProt_AC', 'catalytic_site', 'catalytic_site_resids']\n",
    "].groupby(['UniProt_AC']).agg(set).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5cd6c3-d30f-49d4-8474-28c5c2e4705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csa_in_asd_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0865ec-1ee3-4861-9865-659c312e632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Unique UniProt AC:', df_csa_in_asd_grouped['UniProt_AC'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388b3427-95d7-459e-ac67-7460c784f63c",
   "metadata": {},
   "source": [
    "## Download the Active and Binding Site Data from UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3926212-ede1-4391-a786-97ad3628a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniprot_site_annotations(uniprot_ids):\n",
    "    # Set the SPARQL endpoint (UniProt)\n",
    "    sparql = SPARQLWrapper(\"https://sparql.uniprot.org/sparql\")\n",
    "\n",
    "    output = []\n",
    "    for uniprot_subset in tqdm(itertools.batched(uniprot_ids, 200)):\n",
    "        uniprot_string = ' '.join([f'uniprotkb:{id}' for id in uniprot_subset])\n",
    "                 \n",
    "        # Define the query\n",
    "        query_string = f\"\"\"\n",
    "PREFIX up: <http://purl.uniprot.org/core/>\n",
    "PREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX faldo: <http://biohackathon.org/resource/faldo#>\n",
    "SELECT DISTINCT ?uniprot_id ?begin ?end ?site ?comment\n",
    "WHERE\n",
    "{{\n",
    "    VALUES ?protein {{ {uniprot_string} }}\n",
    "    BIND(substr(str(?protein), strlen(str(uniprotkb:))+1) AS ?uniprot_id)\n",
    "  \n",
    "\t?protein up:annotation ?annotation .\n",
    "  {{ ?annotation a up:Binding_Site_Annotation }} UNION {{ ?annotation a up:Active_Site_Annotation }} .\n",
    "    ?annotation rdf:type ?type .\n",
    "    BIND(substr(str(?type), strlen(str(up:))+1) AS ?site)\n",
    "    ?annotation up:range ?range .\n",
    "\t?range faldo:begin/faldo:position ?begin .\n",
    "\t?range faldo:end/faldo:position ?end .\n",
    "    OPTIONAL\n",
    "    {{\n",
    "        ?annotation up:ligand ?ligand .\n",
    "        ?ligand rdfs:comment ?comment .\n",
    "    }}\n",
    "}}\n",
    "\"\"\"\n",
    "        sparql.setQuery(query_string)\n",
    "    \n",
    "        # Set the output format as JSON\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        \n",
    "        # Run the SPARQL query and convert to the defined format\n",
    "        data = sparql.query().convert()\n",
    "\n",
    "        # Store the query result\n",
    "        for result in data[\"results\"][\"bindings\"]:\n",
    "            output.append({key: value['value'] for key, value in result.items()})\n",
    "    return pd.DataFrame(output, columns=['uniprot_id', 'site', 'begin', 'end', 'comment'])\n",
    "\n",
    "\n",
    "def get_uniprot_sequence(uniprot_ids):\n",
    "    # Set the SPARQL endpoint (UniProt)\n",
    "    sparql = SPARQLWrapper(\"https://sparql.uniprot.org/sparql\")\n",
    "\n",
    "    output = []\n",
    "    for uniprot_subset in tqdm(itertools.batched(uniprot_ids, 200)):\n",
    "        uniprot_string = ' '.join([f'uniprotkb:{id}' for id in uniprot_subset])\n",
    "                 \n",
    "        # Define the query\n",
    "        query_string = f\"\"\"\n",
    "PREFIX up: <http://purl.uniprot.org/core/>\n",
    "PREFIX uniprotkb: <http://purl.uniprot.org/uniprot/>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "SELECT DISTINCT ?uniprot_id ?sequence\n",
    "WHERE\n",
    "{{\n",
    "    VALUES ?protein {{ {uniprot_string} }}\n",
    "    BIND(substr(str(?protein), strlen(str(uniprotkb:))+1) AS ?uniprot_id)\n",
    "    ?protein up:sequence ?isoform .\n",
    "    ?isoform a up:Simple_Sequence ;\n",
    "\t\t\t  rdf:value ?sequence .\n",
    "}}\n",
    "\"\"\"\n",
    "        sparql.setQuery(query_string)\n",
    "    \n",
    "        # Set the output format as JSON\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        \n",
    "        # Run the SPARQL query and convert to the defined format\n",
    "        data = sparql.query().convert()\n",
    "\n",
    "        # Store the query result\n",
    "        for result in data[\"results\"][\"bindings\"]:\n",
    "            output.append({key: value['value'] for key, value in result.items()})\n",
    "    return pd.DataFrame(output, columns=['uniprot_id', 'sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d682d8e-afd8-41c2-8b48-aebbc78a6803",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_ids = {uniprot_id for uniprot_id_list in df_asd_with_active_site['uniprot_in_pdb'].drop_duplicates() for uniprot_id in uniprot_id_list}\n",
    "\n",
    "df_uniprot_site_annotations = get_uniprot_site_annotations(uniprot_ids)\n",
    "df_uniprot_site_annotations.to_csv('../data/UniProt_Site_Annotations.csv', index=False)\n",
    "\n",
    "df_uniprot_sequences = get_uniprot_sequence(uniprot_ids)\n",
    "df_uniprot_sequences.to_csv('../data/UniProt_Sequences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64df100-8976-4d4d-90e1-148c7f74426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_site_annotations = pd.read_csv('../data/UniProt_Site_Annotations.csv')\n",
    "df_uniprot_sequences = pd.read_csv('../data/UniProt_Sequences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89ea5c-d655-470b-b5cc-5bbc7147d3b5",
   "metadata": {},
   "source": [
    "Fix multiple simple sequences returned by UniProt SparQL and use UniProt REST API to fetch the canonical fasta sequence and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f0e785-ebb1-46fa-a385-8c40607ef5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Unique UniProt AC:', df_uniprot_site_annotations['uniprot_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e173d6-2745-4145-b333-74eb8222b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicated_sequences = df_uniprot_sequences[df_uniprot_sequences.duplicated('uniprot_id', keep=False)]\n",
    "for uniprot_id in df_duplicated_sequences['uniprot_id'].unique():\n",
    "    response = requests.get(f'https://rest.uniprot.org/uniprotkb/{uniprot_id}.fasta')\n",
    "    sequence = ''.join(response.text.split('\\n')[1:])\n",
    "    df_uniprot_sequences.loc[df_uniprot_sequences['uniprot_id'] == uniprot_id, 'sequence'] = sequence\n",
    "df_uniprot_sequences.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484437c0-a04b-41ec-bd89-cde72004b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_site_annotations.fillna('', inplace=True)\n",
    "df_uniprot_site_annotations[df_uniprot_site_annotations['comment'].str.contains('alloster')].value_counts('comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5b8fd-c448-44c9-a1db-ae02296521d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique UniProt Accesstion Numbers\n",
    "df_uniprot_site_annotations.loc[df_uniprot_site_annotations['comment'].str.contains('alloster'), 'uniprot_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bfe339-2add-473b-9d79-7c8701094b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_site_annotations[['comment']] = df_uniprot_site_annotations[['comment']].fillna('')\n",
    "\n",
    "df_active_site_annotations = df_uniprot_site_annotations[~df_uniprot_site_annotations['comment'].str.contains('alloster')].copy()\n",
    "\n",
    "df_active_site_annotations['begin'] = df_active_site_annotations['begin'].astype(int)\n",
    "df_active_site_annotations['end'] = df_active_site_annotations['end'].astype(int)\n",
    "\n",
    "# Group the annotation of each UniProt ID in multiple rows \n",
    "active_sites = []\n",
    "for index, group in df_active_site_annotations.groupby(['uniprot_id']):\n",
    "    active_site_residues = []\n",
    "    for _, record in group.iterrows():\n",
    "        # Expand the annotation ranges to list of residue indices\n",
    "        residues = list(range(record['begin'], record['end'] + 1))\n",
    "        active_site_residues.extend(residues)\n",
    "    active_sites.append([index[0], active_site_residues])\n",
    "\n",
    "df_active_sites = pd.DataFrame(active_sites, columns=['uniprot_id', 'active_site_residues'])\n",
    "\n",
    "df_active_sites = df_uniprot_sequences.merge(df_active_sites, how='left')\n",
    "df_active_sites[['active_site_residues']] = df_active_sites[['active_site_residues']].fillna('[]')\n",
    "df_active_sites.to_csv('../output/Active_Sites_from_UniProt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddceb133-9887-4f74-b9f0-aa663d1bc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_site_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2ee770-7b59-4e12-95e4-6e1cdb983d02",
   "metadata": {},
   "source": [
    "## Combine M-CSA and UniProt\n",
    "\n",
    "**Note:** Residue indices listed in M-CSA are in agreement with UniProt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da459261-338a-4ed6-83b7-4d32fc315ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot = pd.read_csv('../output/Active_Sites_from_UniProt.csv')\n",
    "df_uniprot['active_site_residues'] = df_uniprot['active_site_residues'].apply(eval)\n",
    "df_uniprot.rename(columns={'uniprot_id': 'UniProt_AC'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7358260-ba5c-4939-8fbb-ebe1dd9a5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uniprot_csa = df_uniprot.merge(df_csa_in_asd_grouped, how='left', on='UniProt_AC')\n",
    "\n",
    "active_site_residues = []\n",
    "\n",
    "for ind, record in df_uniprot_csa.iterrows():\n",
    "    if record['catalytic_site_resids'] is not np.nan:\n",
    "        catalytic_site_resids = record['catalytic_site_resids']\n",
    "    else:\n",
    "        catalytic_site_resids = set()\n",
    "    active_site_residues.append(sorted(set(record['active_site_residues']) | catalytic_site_resids))\n",
    "\n",
    "df_uniprot_csa['active_site_residues'] = active_site_residues\n",
    "\n",
    "# Remove rows with no active site residues\n",
    "df_uniprot_csa = df_uniprot_csa[(df_uniprot_csa['active_site_residues'].astype(str) != '[]')]\n",
    "\n",
    "df_uniprot_csa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf4186-e01b-4a56-b4cb-9475a2a87862",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asd_with_active_site['uniprot_in_pdb'].apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d218f-6d45-4b13-8d1e-52bdb917380b",
   "metadata": {},
   "source": [
    "## Copy the allosteric site annotation to identical chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bb9864-adcc-4b3d-8cb8-6491f5715bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "\n",
    "allosteric_sites = []\n",
    "for index, record in tqdm(df_asd_with_active_site.iterrows(), total=df_asd_with_active_site.shape[0]):\n",
    "    protein_allosteric_sites = []\n",
    "\n",
    "    site_residues = []\n",
    "    for residue in record['allosteric_site_residues']:\n",
    "        residue = residue.upper()  # Change any lower case residue names or chains to upper case\n",
    "        chain = residue[0]\n",
    "        # Convert chains like '1', '2', ... to 'A', 'B', ...\n",
    "        if chain.isnumeric():\n",
    "            chain = chr(64 + int(chain))\n",
    "            residue = chain + residue[1:]  # Update the chain in the residue\n",
    "        site_residues.append(residue)\n",
    "\n",
    "    # Create a dictionary with chains with each uniprot id\n",
    "    uniprot_to_chains = collections.defaultdict(list)\n",
    "    chains_to_uniprot = collections.defaultdict(list)\n",
    "    for chain, uniprots, seq in record['chain_uniprot_mapping']:\n",
    "        for uniprot_id in uniprots:\n",
    "            uniprot_to_chains[uniprot_id].append(chain)\n",
    "            chains_to_uniprot[chain].append(uniprot_id)\n",
    "\n",
    "    for chain, residues in itertools.groupby(site_residues, key=lambda res: res[0]):\n",
    "        residue_list = list(residues)\n",
    "        for uniprot in chains_to_uniprot[chain]:\n",
    "            for identical_chain in uniprot_to_chains[uniprot]:\n",
    "                protein_allosteric_sites.append([identical_chain, [identical_chain + res[1:] for res in residue_list]])\n",
    "    allosteric_sites.append(protein_allosteric_sites)\n",
    "\n",
    "df_asd_with_active_site['allosteric_sites'] = allosteric_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a9c9af-746b-4698-9e5e-0c05a763f129",
   "metadata": {},
   "source": [
    "## Add active site annotation to identical chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dadb6be-8bae-48df-95e1-e95562ae0e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sites = []\n",
    "for index, record in tqdm(df_asd_with_active_site.iterrows(), total=df_asd_with_active_site.shape[0]):\n",
    "    protein_active_sites = []\n",
    "    for chain in record['chain_uniprot_mapping']:\n",
    "        for uniprot_id in chain[1]:\n",
    "            active_site = df_uniprot_csa.loc[df_uniprot_csa['UniProt_AC'] == uniprot_id, 'active_site_residues']\n",
    "            if not active_site.empty:\n",
    "                protein_active_sites.append([chain[0], list(active_site)[0]])\n",
    "    active_sites.append(protein_active_sites)\n",
    "\n",
    "df_asd_with_active_site['active_sites'] = active_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948604e3-9bfa-4af8-ba31-59b7ff5a5010",
   "metadata": {},
   "source": [
    "Filter the dataframe with at least one allosteric site reidue and one active or binding site residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64adf9f-b7c9-4f1d-a625-5bb8f46463e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with no active site residues\n",
    "df_asd_with_active_site = df_asd_with_active_site[df_asd_with_active_site['active_sites'].str.len() != 0]\n",
    "\n",
    "# Drop the rows with no allosteric site residues\n",
    "df_asd_with_active_site = df_asd_with_active_site[df_asd_with_active_site['allosteric_sites'].str.len() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0820dc-ac98-42bb-8c7b-54e49d6a160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of Rows:             ', df_asd_with_active_site.shape[0])\n",
    "print('Number of Unique PDB IDs:   ', df_asd_with_active_site['allosteric_pdb'].nunique())\n",
    "print('Number of Unique UniProt AC:', df_asd_with_active_site['pdb_uniprot'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5483df7f-ac74-4112-84c9-212e4979364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_asd_with_active_site.to_csv('../output/ASD_with_Active_Sites.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
